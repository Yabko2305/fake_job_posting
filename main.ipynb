{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score,recall_score,confusion_matrix,f1_score,accuracy_score,classification_report,plot_confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Embedding,  Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.optimizers import RMSprop, Adam, SGD\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import pad_sequences\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.utils import pad_sequences\n",
        "from keras.datasets import imdb \n",
        "# fix random seed for reproducibility \n",
        "np.random.seed(4)\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#Handling text \n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from wordcloud import WordCloud,STOPWORDS"
      ],
      "metadata": {
        "id": "BAFm5kzsCiDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKO3A-RQCSUc"
      },
      "outputs": [],
      "source": [
        "data_1 = pd.read_csv(\"/content/drive/MyDrive/ML + BD project data/data_1.csv\",delimiter=',')\n",
        "data_2 = pd.read_csv(\"/content/drive/MyDrive/ML + BD project data/data_2.csv\",delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_1.head()"
      ],
      "metadata": {
        "id": "NsweHDjxCfiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_1.shape"
      ],
      "metadata": {
        "id": "D9FAGG7HClkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2.head()"
      ],
      "metadata": {
        "id": "6OU-tavZCkF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2.shape"
      ],
      "metadata": {
        "id": "bdqOpHa5CoWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2 = data_2.drop(columns=['Unnamed: 0'])\n",
        "data_1 = data_1.drop(columns=['Unnamed: 0'])"
      ],
      "metadata": {
        "id": "Dj0XFzrQDEkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_1.rename(columns = {'company_desc':'company_profile', 'logo':'has_company_logo', 'remote':'telecommuting' }, inplace = True)"
      ],
      "metadata": {
        "id": "-o1rmp_6CrM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_1.head()"
      ],
      "metadata": {
        "id": "MXGSWrlyCySy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([data_1,data_2], axis=0, ignore_index=True)"
      ],
      "metadata": {
        "id": "o57eDo2RDx_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "4TEJkIv9Dy6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "6hbR7n1ID1CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes.to_frame()"
      ],
      "metadata": {
        "id": "b4RFnlGfEJ82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories=['telecommuting','has_company_logo','has_questions','employment_type','required_experience','required_education','industry','function','fraudulent']"
      ],
      "metadata": {
        "id": "Uc1cAXuHEJ0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in categories:\n",
        "     x=data[i].value_counts()\n",
        "     print (x.to_frame())"
      ],
      "metadata": {
        "id": "XUIBz2NSEOsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum()"
      ],
      "metadata": {
        "id": "dZ_ZSV2MEand"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "sns.heatmap(data.isna().transpose())\n",
        "plt.xticks(rotation=45)"
      ],
      "metadata": {
        "id": "2yOb2NFIEfQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "corr = data.corr()\n",
        "sns.heatmap(corr , mask=np.zeros_like(corr, dtype=np.bool) , cmap=sns.diverging_palette(-100,0,as_cmap=True) , square = True)"
      ],
      "metadata": {
        "id": "xMVjV4uvFI8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing undesired columns & nan \n",
        "data.function.fillna(data.department,inplace=True)\n",
        "data.drop(columns=['job_id','salary_range','department'],inplace=True)"
      ],
      "metadata": {
        "id": "Q6gwO4hPFoZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we need to handle missing values for text data and categorical data\n",
        "\n",
        "text=['title','benefits','company_profile','location','description','requirements','fraudulent']\n",
        "\n",
        "categ=['employment_type','required_experience','required_education','industry','function','telecommuting','has_company_logo','has_questions','fraudulent']"
      ],
      "metadata": {
        "id": "VcHMi3AgFrsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filling nan in categorical data\n",
        "categ_cols=data[categ].fillna('None')\n",
        "categ_cols"
      ],
      "metadata": {
        "id": "MsYjwD1DFveG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filling nan in text data\n",
        "txt_cols=data[text].fillna(' ')\n",
        "txt_cols"
      ],
      "metadata": {
        "id": "LUqjru3pFyVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categ_cols['country']=txt_cols['location'].apply(lambda x:x.split(',')[0])\n",
        "countries=categ_cols['country'].value_counts().to_frame()\n",
        "countries"
      ],
      "metadata": {
        "id": "C2LjF1wRF3Wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['fraudulent'].value_counts().to_frame()"
      ],
      "metadata": {
        "id": "AQMHEQigF57O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sns.color_palette('Set2')[0:10]\n",
        "labels=['Real Job','Fake Job']\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.title('Huge Imbalance in Target Values',size=20)\n",
        "sns.set_style('whitegrid')\n",
        "plt.pie(data['fraudulent'].value_counts(),labels=labels,colors=colors,autopct='%.0f%%')"
      ],
      "metadata": {
        "id": "D1hPzLdEF7dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fakejobs=categ_cols[categ_cols['fraudulent']==1]\n",
        "realjobs=categ_cols[categ_cols['fraudulent']==0]"
      ],
      "metadata": {
        "id": "qiMGv4cQF-Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style('darkgrid')\n",
        "fig,axes=plt.subplots(5,2,figsize=(30,50))\n",
        "sns.countplot(fakejobs['country'],palette='Set2',order = fakejobs['country'].value_counts()[:5].index,ax=axes[0,0])\n",
        "sns.countplot(realjobs['country'],palette='Set2',order = realjobs['country'].value_counts()[:5].index,ax=axes[0,1])\n",
        "axes[0,0].set_title('Highest 5 Countries of Fake Jobs',fontsize=15)\n",
        "axes[0,1].set_title('Highest 5 Countries of Real Jobs',fontsize=15)\n",
        "axes[0,0].set_xlabel('Country')\n",
        "axes[0,1].set_xlabel('Country')\n",
        "\n",
        "sns.countplot(fakejobs['employment_type'],palette='Set2',order = fakejobs['employment_type'].value_counts()[:5].index,ax=axes[1,0])\n",
        "sns.countplot(realjobs['employment_type'],palette='Set2',order = realjobs['employment_type'].value_counts()[:5].index,ax=axes[1,1])\n",
        "axes[1,0].set_title('Fake Jobs Most Employment Types',fontsize=15)\n",
        "axes[1,1].set_title('Real Jobs Most Employment Types',fontsize=15)\n",
        "axes[1,0].set_xlabel('Employment Type')\n",
        "axes[1,1].set_xlabel('Employment Type')\n",
        "\n",
        "\n",
        "sns.countplot(fakejobs['required_experience'],palette='Set2',order = fakejobs['required_experience'].value_counts()[1:5].index,ax=axes[2,0])\n",
        "sns.countplot(realjobs['required_experience'],palette='Set2',order = realjobs['required_experience'].value_counts()[1:5].index,ax=axes[2,1])\n",
        "axes[2,0].set_title('Fake Jobs Most Required Experience',fontsize=15)\n",
        "axes[2,1].set_title('Real Jobs Most Required Experience',fontsize=15)\n",
        "axes[2,0].set_xlabel('Required Experience')\n",
        "axes[2,1].set_xlabel('Required Experience')\n",
        "\n",
        "sns.countplot(fakejobs['industry'],palette='Set2',order = fakejobs['industry'].value_counts()[1:5].index,ax=axes[3,0])\n",
        "sns.countplot(realjobs['industry'],palette='Set2',order = realjobs['industry'].value_counts()[1:5].index,ax=axes[3,1])\n",
        "axes[3,0].set_title('Fake Jobs Most Industries',fontsize=15)\n",
        "axes[3,1].set_title('Real Jobs Most Industries',fontsize=15)\n",
        "axes[3,0].set_xlabel('Industryy')\n",
        "axes[3,1].set_xlabel('Industry')\n",
        "\n",
        "sns.countplot(fakejobs['function'],palette='Set2',order = fakejobs['function'].value_counts()[1:5].index,ax=axes[4,0])\n",
        "sns.countplot(realjobs['function'],palette='Set2',order = realjobs['function'].value_counts()[1:5].index,ax=axes[4,1])\n",
        "axes[4,0].set_title('Fake Jobs Most Functions',fontsize=15)\n",
        "axes[4,1].set_title('Real Jobs Most Functions',fontsize=15)\n",
        "axes[4,0].set_xlabel('Function')\n",
        "axes[4,1].set_xlabel('Function')\n",
        "\n",
        "# AU --> Austrilia\n",
        "# GB --> United Kingdom\n",
        "# GR --> Greece\n",
        "# CA --> Canada\n",
        "# MY --> Malaysia"
      ],
      "metadata": {
        "id": "3746bj-uGAsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,axes=plt.subplots(1,3,figsize=(21,7))\n",
        "sns.countplot(x='telecommuting', data=categ_cols, hue='fraudulent', palette='Set2',ax=axes[0]) \n",
        "sns.countplot(x='has_company_logo', data=categ_cols, hue='fraudulent', palette='Set2',ax=axes[1]) \n",
        "sns.countplot(x='has_questions', data=categ_cols, hue='fraudulent', palette='Set2',ax=axes[2]) \n",
        "\n",
        "axes[0].set_title('Telecommuting',fontsize=12)\n",
        "axes[1].set_title('Has Company Logo?',fontsize=12)\n",
        "axes[2].set_title('Has Questions?',fontsize=12)\n",
        "\n",
        "axes[0].set_xlabel('')\n",
        "axes[1].set_xlabel('')\n",
        "axes[2].set_xlabel('')"
      ],
      "metadata": {
        "id": "YW8ua6jyGHr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp_list=['Executive','Associate','Director','Mid-Senior level']\n",
        "exp_data=categ_cols.loc[categ_cols['required_experience'].isin(exp_list)]"
      ],
      "metadata": {
        "id": "MG3Gz59JGN1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp_data_indus=exp_data.groupby('industry')['required_experience'].value_counts(ascending=False).to_frame()\n",
        "exp_data_indus.head(30)"
      ],
      "metadata": {
        "id": "QT9mVK9UGPcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp_data_fun=exp_data.groupby('function')['required_experience'].value_counts(ascending=False).to_frame()\n",
        "exp_data_fun.head(30)"
      ],
      "metadata": {
        "id": "62sDNmBeGSBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categ_cols.groupby('country')['employment_type'].value_counts(ascending=False).to_frame().head(50)"
      ],
      "metadata": {
        "id": "YtzQK4oaGW_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categ_cols.groupby('industry')['required_education'].value_counts(ascending=False).to_frame().head(50)"
      ],
      "metadata": {
        "id": "tbftKKX-GaL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oOG1ghVnGfY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As we used Country in location column as a category data\n",
        "cols_to_remove=['location']\n",
        "txt_cols.drop(columns=cols_to_remove,inplace=True) "
      ],
      "metadata": {
        "id": "3gms8-T_GgU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer=PorterStemmer()\n",
        "stop=set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "QeOov-AgGjYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def column_clean(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('[^a-zA-Z\\s*]','',text)\n",
        "    text=text.split()\n",
        "    text=[stemmer.stem(word) for word in text if word not in set(stopwords.words('english'))]\n",
        "    return (text)"
      ],
      "metadata": {
        "id": "tK3sOVujGkUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting Text Data to Fraud or Not Fraud\n",
        "txt_fraud=txt_cols[txt_cols['fraudulent']==1]\n",
        "txt_not_fraud=txt_cols[txt_cols['fraudulent']==0]"
      ],
      "metadata": {
        "id": "SgWt6IA-Gq0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_fraud['title']=txt_fraud['title'].apply(column_clean)\n",
        "txt_not_fraud['title']=txt_not_fraud['title'].apply(column_clean)"
      ],
      "metadata": {
        "id": "uyhnAC-9Grzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine(list_of_text):\n",
        "    combined_text = ' '.join(list_of_text)\n",
        "    return combined_text\n",
        "\n",
        "fraud_titles = txt_fraud['title'].apply(combine)\n",
        "not_fraud_titles = txt_not_fraud['title'].apply(combine)"
      ],
      "metadata": {
        "id": "zFXL1ONtGsxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraud_titles"
      ],
      "metadata": {
        "id": "jBaPeccMGt_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To List\n",
        "\n",
        "fraud_titles_corpus=fraud_titles.values.tolist()\n",
        "not_fraud_titles_corpus=not_fraud_titles.values.tolist()"
      ],
      "metadata": {
        "id": "17kAfNEJGwg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corpus for WordCloud\n",
        "fraud_titles_corpus=' '.join(fraud_titles_corpus)\n",
        "not_fraud_titles_corpus=' '.join(not_fraud_titles_corpus)"
      ],
      "metadata": {
        "id": "7aH-KJWbGxbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "wordcloudfraud=WordCloud(width = 1900 , height = 1200 , background_color='white').generate(fraud_titles_corpus)\n",
        "plt.axis('off')\n",
        "plt.title('Most Common titles words in Fake jobs',size=20)\n",
        "plt.imshow(wordcloudfraud)"
      ],
      "metadata": {
        "id": "6f_b9m1AGy6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "wordcloudnotfraud=WordCloud(width = 1900 , height = 1200,background_color='white').generate(not_fraud_titles_corpus)\n",
        "plt.axis('off')\n",
        "plt.title('Most Common titles words in Real jobs',size=20)\n",
        "plt.imshow(wordcloudnotfraud)"
      ],
      "metadata": {
        "id": "3kZjrKktG1NX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraud_title_length=txt_cols[txt_cols[\"fraudulent\"]==1]['title'].str.len()\n",
        "not_fraud_title_length=txt_cols[txt_cols[\"fraudulent\"]==0]['title'].str.len()\n",
        "\n",
        "fig,axes=plt.subplots(1,2,figsize=(21,7))\n",
        "sns.kdeplot(fraud_title_length,ax=axes[0],color='black') \n",
        "sns.kdeplot(not_fraud_title_length,ax=axes[1],color='black') \n",
        "\n",
        "axes[0].set_title('Fake Title Lengths',fontsize=12)\n",
        "axes[1].set_title('Not Fake Titles Lengths',fontsize=12)"
      ],
      "metadata": {
        "id": "WtCBC5CqG561"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_fraud['benefits']=txt_fraud['benefits'].apply(column_clean)\n",
        "txt_not_fraud['benefits']=txt_not_fraud['benefits'].apply(column_clean)"
      ],
      "metadata": {
        "id": "xrcFdQSvHFWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraud_benefits = txt_fraud['benefits'].apply(combine)\n",
        "not_fraud_benefits = txt_not_fraud['benefits'].apply(combine)"
      ],
      "metadata": {
        "id": "2D7xojf0HGpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To List\n",
        "\n",
        "fraud_benefits_corpus=fraud_benefits.values.tolist()\n",
        "not_fraud_benefits_corpus=not_fraud_benefits.values.tolist()"
      ],
      "metadata": {
        "id": "z66PIhO5HIG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corpus for WordCloud\n",
        "fraud_benefits_corpus=' '.join(fraud_benefits_corpus)\n",
        "not_fraud_benefits_corpus=' '.join(not_fraud_benefits_corpus)"
      ],
      "metadata": {
        "id": "z5AexjSRHJIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "wordcloud_fraud_ben=WordCloud(width = 1900 , height = 1200,background_color='white').generate(fraud_benefits_corpus)\n",
        "plt.axis('off')\n",
        "plt.title('Most Common Words in Benefits in Fake jobs',size=20)\n",
        "plt.imshow(wordcloud_fraud_ben)"
      ],
      "metadata": {
        "id": "5DzS-jyxHa3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "wordcloud_notfraudben=WordCloud(width = 1900 , height = 1200,background_color='white').generate(not_fraud_benefits_corpus)\n",
        "plt.axis('off')\n",
        "plt.title('Most Common Words in Benefits in Real jobs',size=20)\n",
        "plt.imshow(wordcloud_notfraudben)"
      ],
      "metadata": {
        "id": "XU6TyAy1Hb7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraud_benefits_length=txt_cols[txt_cols[\"fraudulent\"]==1]['benefits'].str.len()\n",
        "not_fraud_benefits_length=txt_cols[txt_cols[\"fraudulent\"]==0]['benefits'].str.len()\n",
        "\n",
        "fig,axes=plt.subplots(1,2,figsize=(21,7))\n",
        "sns.kdeplot(fraud_benefits_length,ax=axes[0],color='black') \n",
        "sns.kdeplot(not_fraud_benefits_length,ax=axes[1],color='black') \n",
        "\n",
        "axes[0].set_title('Fake Benefits Lengths',fontsize=12)\n",
        "axes[1].set_title('Real Benefits Lengths',fontsize=12)"
      ],
      "metadata": {
        "id": "h2vJQVdIHdXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_fraud['company_profile']=txt_fraud['company_profile'].apply(column_clean)\n",
        "txt_not_fraud['company_profile']=txt_not_fraud['company_profile'].apply(column_clean)"
      ],
      "metadata": {
        "id": "58jSp57THfte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraud_company = txt_fraud['company_profile'].apply(combine)\n",
        "not_fraud_company = txt_not_fraud['company_profile'].apply(combine)"
      ],
      "metadata": {
        "id": "KXRYWE8PHhwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To List\n",
        "\n",
        "fraud_company_corpus=fraud_company.values.tolist()\n",
        "not_fraud_company_corpus=not_fraud_company.values.tolist()"
      ],
      "metadata": {
        "id": "T3pAc-aSHi5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corpus for WordCloud\n",
        "fraud_company_corpus=' '.join(fraud_company_corpus)\n",
        "not_fraud_company_corpus=' '.join(not_fraud_company_corpus)"
      ],
      "metadata": {
        "id": "s5i30br3Hj2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "wordcloud_fraud_company=WordCloud(width = 1900 , height = 1200,background_color='white').generate(fraud_company_corpus)\n",
        "plt.axis('off')\n",
        "plt.title('Most Common Words in Company Profile in Fake jobs',size=20)\n",
        "plt.imshow(wordcloud_fraud_company)"
      ],
      "metadata": {
        "id": "m4Dc0LjGHlFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "wordcloud_not_fraud_company=WordCloud(width = 1900 , height = 1200,background_color='white').generate(not_fraud_company_corpus)\n",
        "plt.axis('off')\n",
        "plt.title('Most Common Words in Company Profile in Real jobs',size=20)\n",
        "plt.imshow(wordcloud_not_fraud_company)"
      ],
      "metadata": {
        "id": "yrTvKApXHmUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraud_company_length=txt_cols[txt_cols[\"fraudulent\"]==1]['company_profile'].str.len()\n",
        "not_fraud_company_length=txt_cols[txt_cols[\"fraudulent\"]==0]['company_profile'].str.len()\n",
        "\n",
        "fig,axes=plt.subplots(1,2,figsize=(21,7))\n",
        "sns.kdeplot(fraud_company_length,ax=axes[0],color='black') \n",
        "sns.kdeplot(not_fraud_company_length,ax=axes[1],color='black') \n",
        "\n",
        "axes[0].set_title('Fake Company Profile Lengths',fontsize=12)\n",
        "axes[1].set_title('Real Company Profile Lengths?',fontsize=12)"
      ],
      "metadata": {
        "id": "s558VhAHHoN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_fraud['requirements']=txt_fraud['requirements'].apply(column_clean)\n",
        "txt_not_fraud['requirements']=txt_not_fraud['requirements'].apply(column_clean)"
      ],
      "metadata": {
        "id": "Tvb6xfNqHq7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraud_requirements = txt_fraud['requirements'].apply(combine)\n",
        "not_fraud_requirements = txt_not_fraud['requirements'].apply(combine)"
      ],
      "metadata": {
        "id": "c9IGVXwDHrvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To List\n",
        "\n",
        "fraud_requirements_corpus=fraud_requirements.values.tolist()\n",
        "not_fraud_requirements_corpus=not_fraud_requirements.values.tolist()"
      ],
      "metadata": {
        "id": "RqMCjoREHsyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corpus for WordCloud\n",
        "fraud_requirements_corpus=' '.join(fraud_requirements_corpus)\n",
        "not_fraud_requirements_corpus=' '.join(not_fraud_requirements_corpus)"
      ],
      "metadata": {
        "id": "clENDumAHuJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "wordcloud_fraud_requirements=WordCloud(width = 1900 , height = 1200,background_color='white').generate(fraud_requirements_corpus)\n",
        "plt.axis('off')\n",
        "plt.title('Most Common Words in Requirements in Fake jobs',size=20)\n",
        "plt.imshow(wordcloud_fraud_requirements)"
      ],
      "metadata": {
        "id": "0b34F4yqHvcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "wordcloud_notfraud_requirements=WordCloud(width = 1900 , height = 1200,background_color='white').generate(not_fraud_requirements_corpus)\n",
        "plt.axis('off')\n",
        "plt.title('Most Common Words in Requirements in Real jobs',size=20)\n",
        "plt.imshow(wordcloud_notfraud_requirements)"
      ],
      "metadata": {
        "id": "VJfsCkv1Hxhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t-kx8otCH01k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=txt_cols.join(categ_cols.drop(columns='fraudulent'))"
      ],
      "metadata": {
        "id": "VdsoCotpH0TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text']=data['title'] +' '+data['benefits']+' '+data['company_profile']+' '+data['description']+' '+data['requirements']\n",
        "colm=['title','benefits','company_profile','description','requirements']\n",
        "data.drop(columns=colm,inplace=True)"
      ],
      "metadata": {
        "id": "3sA1PMz1H2ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text']=data['text'].apply(column_clean)"
      ],
      "metadata": {
        "id": "ZcoQkLRoH45D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text']=data['text'].apply(combine)"
      ],
      "metadata": {
        "id": "sZ7_iQokH6rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,10)) \n",
        "wordcloud_real = WordCloud(width = 1600 , height = 800 , max_words = 500,background_color='white').generate(\" \".join(data[data['fraudulent'] == 0]['text']))\n",
        "plt.axis('off')\n",
        "plt.title('Most Common Words in Real jobs',size=20)\n",
        "plt.imshow(wordcloud_real)"
      ],
      "metadata": {
        "id": "Q7ji6WdmH7r6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,10)) \n",
        "wordcloud_fake = WordCloud(width = 1600 , height = 800 , max_words = 500,background_color='white').generate(\" \".join(data[data['fraudulent'] == 1]['text']))\n",
        "plt.axis('off')\n",
        "plt.title('Most Common Words in Fake jobs',size=20)\n",
        "plt.imshow(wordcloud_fake)"
      ],
      "metadata": {
        "id": "twj_B3ZrH9Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rl1Tye_pH_AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=data.drop(columns='fraudulent')\n",
        "y=data['fraudulent']"
      ],
      "metadata": {
        "id": "GFP2RR1aH-qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Count Vectorizer\n",
        "count_vec = CountVectorizer(max_features=5000)\n",
        "vec = count_vec.fit_transform(data['text'])"
      ],
      "metadata": {
        "id": "S6_CpM_jH_ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=pd.DataFrame(vec.toarray(),columns=count_vec.get_feature_names_out())"
      ],
      "metadata": {
        "id": "5kThWzpuIBR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=pd.get_dummies(x.drop(columns='text'))\n",
        "result = pd.concat([labels, text], axis=1)"
      ],
      "metadata": {
        "id": "FVbbSS82ICO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data to train and test\n",
        "x_train,x_test,y_train,y_test=train_test_split(result,y,test_size=0.2,random_state=42,stratify=y)"
      ],
      "metadata": {
        "id": "vTDSHfc3IDDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Yqsz6cHIHns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes\n",
        "nb=MultinomialNB()\n",
        "nb.fit(x_train,y_train)\n",
        "nb_y_pred=nb.predict(x_test)"
      ],
      "metadata": {
        "id": "yrvQ_jpkIHzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('        Training Classification report for Naive Bayes \\n',classification_report(y_train,nb.predict(x_train)))\n",
        "print('        Testing Classification Report for Naive Bayes \\n',classification_report(y_test,nb_y_pred))\n",
        "\n",
        "print('        Confusion Matrix for Training Naive Bayes \\n',plot_confusion_matrix(nb,x_train,y_train))\n",
        "print('        Confusion Matrix for Testing Naive Bayes \\n',plot_confusion_matrix(nb,x_test,y_test))"
      ],
      "metadata": {
        "id": "kx3SJwmVIIxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "lr=LogisticRegression()\n",
        "lr.fit(x_train,y_train)\n",
        "lr_y_pred=lr.predict(x_test)"
      ],
      "metadata": {
        "id": "Cl9e7paYIKdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('        Training Classification report for Logistic Regression \\n',classification_report(y_train,lr.predict(x_train)))\n",
        "print('        Testing Classification Report for Logistion Regression \\n',classification_report(y_test,lr_y_pred))\n",
        "\n",
        "print('        Confusion Matrix for Training Logistic Regression \\n',plot_confusion_matrix(lr,x_train,y_train))\n",
        "print('        Confusion Matrix for Testing Logistic Regression \\n',plot_confusion_matrix(lr,x_test,y_test))"
      ],
      "metadata": {
        "id": "rrjz-0S2ILaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN\n",
        "knn= KNeighborsClassifier()\n",
        "knn.fit(x_train,y_train)\n",
        "knn_y_pred=knn.predict(x_test)"
      ],
      "metadata": {
        "id": "KEBWmPsNINAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('        Training Classification report for KNN \\n',classification_report(y_train,lr.predict(x_train)))\n",
        "print('        Testing Classification Report for KNN \\n',classification_report(y_test,knn_y_pred))\n",
        "\n",
        "print('        Confusion Matrix for Training KNN \\n',plot_confusion_matrix(knn,x_train,y_train))\n",
        "print('        Confusion Matrix for Testing KNN \\n',plot_confusion_matrix(knn,x_test,y_test))"
      ],
      "metadata": {
        "id": "BFXao9SpIOC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DecisionTreeClassifier\n",
        "dt=DecisionTreeClassifier()\n",
        "dt.fit(x_train,y_train)\n",
        "dt_y_pred=dt.predict(x_test)"
      ],
      "metadata": {
        "id": "e_sHCMK8IdUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('        Training Classification report for Decision Tree Classifier \\n',classification_report(y_train,dt.predict(x_train)))\n",
        "print('        Testing Classification Report for Decision Tree Classifier \\n',classification_report(y_test,dt_y_pred))\n",
        "print('        Confusion Matrix for Training Decision Tree Classifier \\n',plot_confusion_matrix(dt,x_train,y_train))\n",
        "print('        Confusion Matrix for Testing Decision Tree Classifier\\n',plot_confusion_matrix(dt,x_test,y_test))"
      ],
      "metadata": {
        "id": "M22_Ags8IeWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf=RandomForestClassifier()\n",
        "rf.fit(x_train,y_train)\n",
        "rf_y_pred=rf.predict(x_test)"
      ],
      "metadata": {
        "id": "SlrtGmndIgLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('        Training Classification report for Random Forest Classifier \\n',classification_report(y_train,rf.predict(x_train)))\n",
        "print('        Testing Classification Report for Random Forest Classifier \\n',classification_report(y_test,rf_y_pred))\n",
        "\n",
        "\n",
        "print('        Confusion Matrix for Training Random Forest Classifier \\n',plot_confusion_matrix(rf,x_train,y_train))\n",
        "print('        Confusion Matrix for Testing Random Foresr Classifier\\n',plot_confusion_matrix(rf,x_test,y_test))"
      ],
      "metadata": {
        "id": "CadhtVenIo-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.head()"
      ],
      "metadata": {
        "id": "TogJ99IGIkKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb=xgb.XGBClassifier(max_depth=6, learning_rate=0.1,silent=False, objective='binary:logistic')\n",
        "xgb.fit(x_train,y_train)\n",
        "xgb_y_pred=xgb.predict(x_test)"
      ],
      "metadata": {
        "id": "ZOxRUxyfMD_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('        Training Classification report for XGBoost Classifier \\n',classification_report(y_train,xgb.predict(x_train)))\n",
        "print('        Testing Classification Report for XGBoost Classifier \\n',classification_report(y_test,xgb_y_pred))\n",
        "\n",
        "\n",
        "print('        Confusion Matrix for Training XGBoost Classifier \\n',plot_confusion_matrix(xgb,x_train,y_train))\n",
        "print('        Confusion Matrix for Testing XGBoost Classifier\\n',plot_confusion_matrix(xgb,x_test,y_test))"
      ],
      "metadata": {
        "id": "O2Z5D4pWME70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ada=AdaBoostClassifier()\n",
        "ada.fit(x_train,y_train)\n",
        "ada_y_pred=ada.predict(x_test)"
      ],
      "metadata": {
        "id": "budrcHg9MHgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('        Training Classification report for AdaBoost Classifier \\n',classification_report(y_train,ada.predict(x_train)))\n",
        "print('        Testing Classification Report for AdaBoost Classifier \\n',classification_report(y_test,ada_y_pred))\n",
        "\n",
        "\n",
        "print('        Confusion Matrix for Training AdaBoost Classifier \\n',plot_confusion_matrix(ada,x_train,y_train))\n",
        "print('        Confusion Matrix for Testing AdaBoost Classifier\\n',plot_confusion_matrix(ada,x_test,y_test))"
      ],
      "metadata": {
        "id": "zq91NWRTMH8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "WV7WYNhG84bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 10000\n",
        "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
        "\n",
        "# create the tokenizer\n",
        "t = Tokenizer(num_words = max_features)\n",
        "# fit the tokenizer on the documents\n",
        "t.fit_on_texts(data['text'].values)"
      ],
      "metadata": {
        "id": "DAnc4S4GMJRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['word count'] = [len(i.split(' ')) for i in data['text']]\n",
        "sent_length = data['word count'].max()"
      ],
      "metadata": {
        "id": "hnaE6X45-aJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_docs = t.texts_to_sequences(data['text'].values)\n",
        "embedded_docs=pad_sequences(encoded_docs,padding='pre',maxlen=sent_length)\n",
        "print(embedded_docs)"
      ],
      "metadata": {
        "id": "_nWkvoMn-Ls2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = data['fraudulent'].values\n",
        "y"
      ],
      "metadata": {
        "id": "QtbwFFLW-jms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = y.reshape(-1,1)\n",
        "y.shape"
      ],
      "metadata": {
        "id": "_S_TaVzc-nmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(embedded_docs)\n",
        "X.shape"
      ],
      "metadata": {
        "id": "sJrdk6R1-obh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.1, random_state= 101)"
      ],
      "metadata": {
        "id": "MM9ZsrpT-qWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape: \",X_train.shape)\n",
        "print(\"X_test shape : \",X_test.shape )\n",
        "print(\"y_train shape: \",y_train.shape)\n",
        "print(\"y_test shape : \",y_test.shape)"
      ],
      "metadata": {
        "id": "dFfj2eOj-r2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_metrics(actual, prediction):\n",
        "    print(\"Accuracy Score: {}\".format(accuracy_score(actual, prediction)))\n",
        "    print(\"Recall Score: {}\".format(recall_score(actual, prediction)))\n",
        "    print(\"f1 Score: {}\".format(f1_score(actual, prediction)))"
      ],
      "metadata": {
        "id": "eLGbzxIU-tBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vector_features=40\n",
        "model1=Sequential()\n",
        "model1.add(Embedding(max_features,embedding_vector_features,input_length=sent_length))\n",
        "model1.add(Bidirectional(LSTM(20)))\n",
        "model1.add(Dense(1,activation='sigmoid'))\n",
        "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print(model1.summary())"
      ],
      "metadata": {
        "id": "wMHELIi8_BUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "xx-HmgeC_X12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "hist = model1.fit(X_train, y_train, epochs = 5, batch_size = 64, validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "id": "xmxsYSiN_ZCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['val_loss'], color='b', label=\"validation loss\")\n",
        "plt.plot(hist.history['loss'], color='red', label=\"loss\")\n",
        "plt.title(\"Model Loss\")\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vjAfbOrL_cZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['val_accuracy'], color='b', label=\"validation accuracy\")\n",
        "plt.plot(hist.history['accuracy'], color='red', label=\"accuracy\")\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U-42ap7r_d23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model1.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)"
      ],
      "metadata": {
        "id": "Ty56E3um_mIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model1.predict(X_train)\n",
        "y_train_pred = (y_train_pred > 0.5)"
      ],
      "metadata": {
        "id": "9wwwonQi_nsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "fS8NUTiJJvBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('        Training Classification report for Bidirectional LSTM \\n',classification_report(y_train,y_train_pred))\n",
        "print('        Testing Classification Report for Bidirectional LSTM \\n',classification_report(y_test,y_pred))\n",
        "\n",
        "\n",
        "\n",
        "print('        Confusion Matrix for Testing Bidirectional LSTM \\n')\n",
        "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                               display_labels=[0,1])\n",
        "disp.plot()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xgxcAlJN_uGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('        Confusion Matrix for Training Bidirectional LSTMr\\n')\n",
        "cm = confusion_matrix(y_train, y_train_pred, labels=[0,1])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                               display_labels=[0,1])\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K93myqEbJ9ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vector_features=40\n",
        "model2=Sequential()\n",
        "model2.add(Embedding(max_features,embedding_vector_features,input_length=sent_length))\n",
        "model2.add(LSTM(25))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print(model2.summary())\n"
      ],
      "metadata": {
        "id": "__0wF2kjM1qV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "hist = model2.fit(X_train, y_train, epochs = 5, batch_size = 64, validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "id": "8yi8qYWWNc6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['val_loss'], color='b', label=\"validation loss\")\n",
        "plt.plot(hist.history['loss'], color='red', label=\"loss\")\n",
        "plt.title(\"Model Loss\")\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuEHEPJEN95V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['val_accuracy'], color='b', label=\"validation accuracy\")\n",
        "plt.plot(hist.history['accuracy'], color='red', label=\"accuracy\")\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O7n1axImN_Nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model2.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "y_train_pred = model2.predict(X_train)\n",
        "y_train_pred = (y_train_pred > 0.5)"
      ],
      "metadata": {
        "id": "10BLnMkMOAj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('        Training Classification report for LSTM \\n',classification_report(y_train,y_train_pred))\n",
        "print('        Testing Classification Report for LSTM \\n',classification_report(y_test,y_pred))\n",
        "\n",
        "\n",
        "\n",
        "print('        Confusion Matrix for Testing LSTM \\n')\n",
        "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                               display_labels=[0,1])\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wXE5ODRJOCNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('        Confusion Matrix for Training LSTMr\\n')\n",
        "cm = confusion_matrix(y_train, y_train_pred, labels=[0,1])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                               display_labels=[0,1])\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tLGBk2EqOFXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vector_features=40\n",
        "model3=Sequential()\n",
        "model3.add(Embedding(max_features,embedding_vector_features,input_length=sent_length))\n",
        "model3.add(Dense(256))\n",
        "model3.add(Bidirectional(LSTM(25)))\n",
        "model3.add(Dense(1, activation='sigmoid'))\n",
        "model3.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print(model3.summary())"
      ],
      "metadata": {
        "id": "Kua9orYlOJ40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "hist = model3.fit(X_train, y_train, epochs = 5, batch_size = 64, validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "id": "AGh4vdI0OWsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['val_loss'], color='b', label=\"validation loss\")\n",
        "plt.plot(hist.history['loss'], color='red', label=\"loss\")\n",
        "plt.title(\"Model Loss\")\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0pGsZbTgOabQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['val_accuracy'], color='b', label=\"validation accuracy\")\n",
        "plt.plot(hist.history['accuracy'], color='red', label=\"accuracy\")\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "98yfmEX5OcBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model1.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "y_train_pred = model1.predict(X_train)\n",
        "y_train_pred = (y_train_pred > 0.5)"
      ],
      "metadata": {
        "id": "jaunI_lsOdVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('        Training Classification report for Bidirectional LSTM \\n',classification_report(y_train,y_train_pred))\n",
        "print('        Testing Classification Report for Bidirectional LSTM \\n',classification_report(y_test,y_pred))\n",
        "\n",
        "\n",
        "\n",
        "print('        Confusion Matrix for Testing Bidirectional LSTM \\n')\n",
        "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                               display_labels=[0,1])\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q0YO7yabOfIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('        Confusion Matrix for Training Bidirectional LSTMr\\n')\n",
        "cm = confusion_matrix(y_train, y_train_pred, labels=[0,1])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                               display_labels=[0,1])\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RitShxnWOgSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "def create_base_model(activation = 'tanh',  loss='binary_crossentropy', optimizer = \"Adam\", lr = 0.01):\n",
        "  embedding_vector_features=40\n",
        "  model=Sequential()\n",
        "  model.add(Embedding(max_features,40,input_length=sent_length))\n",
        "  model.add(LSTM(25, activation = activation))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss=loss,optimizer=optimizer,metrics=['accuracy'])\n",
        "  K.set_value(model.optimizer.learning_rate, lr)\n",
        "  return model\n",
        "\n",
        "def k_fold_test(X, y, epochs = 5, batch_size = 64, activation = 'tanh', loss='binary_crossentropy', optimizer = \"Adam\", lr = 0.01):\n",
        "  from sklearn.model_selection import StratifiedKFold,KFold\n",
        "  k_fold_index = StratifiedKFold(n_splits = 5,shuffle=True,random_state=42)\n",
        "  early_stopping_monitor = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=2,\n",
        "    verbose=1,\n",
        "  )\n",
        "  val_accuracy = 0\n",
        "  for train_index, test_index in k_fold_index.split(X,y):\n",
        "    x_train, x_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = create_base_model(activation, loss, optimizer)\n",
        "    hist = model.fit(x_train, y_train, epochs = epochs, batch_size = batch_size, validation_data=(x_test,y_test), callbacks=[early_stopping_monitor])\n",
        "\n",
        "    val_accuracy += max(hist.history['val_accuracy'])\n",
        "\n",
        "  val_accuracy = val_accuracy/5\n",
        "\n",
        "  return val_accuracy"
      ],
      "metadata": {
        "id": "6lzwTBVfaoJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras import optimizers\n",
        "\n",
        "# epochs = [5,10]\n",
        "# activations = ['tanh']\n",
        "# optimizers_arr = [\"Adam\", \"SGD\"]\n",
        "# lrs = [0.1, 0.01, 0.001]\n"
      ],
      "metadata": {
        "id": "tLpMcBXOeOL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# results = []\n",
        "# for e in epochs:\n",
        "#   for a in activations:\n",
        "#     for o in optimizers_arr:\n",
        "#       for l in lrs:\n",
        "#         val =  k_fold_test(X, y, epochs = e, batch_size = 64, activation = a, loss='binary_crossentropy', optimizer = o, lr = l)\n",
        "#         x = 'Epochs: ' + str(e) + ' Activation function: ' + str(a) + ' Optimizer: ' + str(o) + ' LR: ' + str(l) + ' Cross-validational test accuracy: ' + str(val)\n",
        "#         results.append(x) \n",
        "#         print(x)"
      ],
      "metadata": {
        "id": "MzK-20Dinl6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vector_features=40\n",
        "model=Sequential()\n",
        "model.add(Embedding(max_features,40,input_length=sent_length))\n",
        "model.add(LSTM(25, activation = 'tanh'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
        "K.set_value(model.optimizer.learning_rate, 0.001)"
      ],
      "metadata": {
        "id": "77yoXhfZvOM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_monitor = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=2,\n",
        "    verbose=1,\n",
        "  )\n",
        "hist = model.fit(X_train, y_train, epochs = 10, batch_size = 60, validation_data=(X_test,y_test), callbacks=[early_stopping_monitor])"
      ],
      "metadata": {
        "id": "8B0AwkbtvuPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['val_loss'], color='b', label=\"validation loss\")\n",
        "plt.plot(hist.history['loss'], color='red', label=\"loss\")\n",
        "plt.title(\"Model Loss\")\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OR5NaQuFwFrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['val_accuracy'], color='b', label=\"validation accuracy\")\n",
        "plt.plot(hist.history['accuracy'], color='red', label=\"accuracy\")\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d2TVOF2-wI2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model1.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "y_train_pred = model1.predict(X_train)\n",
        "y_train_pred = (y_train_pred > 0.5)"
      ],
      "metadata": {
        "id": "gVwsc_1OwLPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('        Training Classification report for Bidirectional LSTM \\n',classification_report(y_train,y_train_pred))\n",
        "print('        Testing Classification Report for Bidirectional LSTM \\n',classification_report(y_test,y_pred))\n",
        "\n",
        "\n",
        "\n",
        "print('        Confusion Matrix for Testing Bidirectional LSTM \\n')\n",
        "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                               display_labels=[0,1])\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8eXXT3fZwPGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('        Confusion Matrix for Training Bidirectional LSTMr\\n')\n",
        "cm = confusion_matrix(y_train, y_train_pred, labels=[0,1])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                               display_labels=[0,1])\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7cdn4rgXwRd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = [i for i, (y1, y2) in enumerate(zip(y_test, y_pred)) if y1 == 0 and y2 == 1]"
      ],
      "metadata": {
        "id": "L8-CaomhFZrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(indices)"
      ],
      "metadata": {
        "id": "_KPRqJuQGjso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test[96])"
      ],
      "metadata": {
        "id": "YgUPYS08GnTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[97]"
      ],
      "metadata": {
        "id": "sHBdVMgdGwS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = data[data['fraudulent'] == 1]"
      ],
      "metadata": {
        "id": "3P4TTN7yHafI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_f['text'].head()"
      ],
      "metadata": {
        "id": "8k2fov1THr7R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}